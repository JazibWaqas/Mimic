"""
Gemini Advisor: Strategic clip selection guidance system.

The Advisor provides high-level suggestions that BIAS the matcher
without replacing it. This maintains determinism while adding
narrative intelligence.
"""

import json
import hashlib
from pathlib import Path
from typing import Optional, Tuple
from datetime import datetime

from models import (
    StyleBlueprint,
    ClipIndex,
    ClipMetadata,
    Segment,
    AdvisorHints,
    ArcStageGuidance,
    LibraryAssessment,
    CreativeAudit
)
from engine.gemini_advisor_prompt import ADVISOR_PROMPT
from engine.brain import initialize_gemini, _parse_json_response, GeminiConfig, rate_limiter, _handle_rate_limit_error
import time


def get_advisor_suggestions(
    blueprint: StyleBlueprint,
    clip_index: ClipIndex,
    cache_dir: Optional[Path] = None,
    force_refresh: bool = False,
    scarcity_report: Optional[dict] = None
) -> Optional[AdvisorHints]:
    """
    Get Gemini's strategic suggestions for clip selection.
    
    This generates or retrieves cached advisor hints that influence
    the matcher's scoring without controlling it.
    
    Args:
        blueprint: Analyzed reference structure with narrative intent
        clip_index: Analyzed user clips with semantic metadata
        cache_dir: Directory for caching advisor results (defaults to root data/cache/advisor)
        force_refresh: If True, bypass cache and regenerate
    
    Returns:
        AdvisorHints if successful, None if failure (graceful degradation)
    """
    if cache_dir is None:
        BASE_DIR = Path(__file__).resolve().parent.parent.parent
        cache_dir = BASE_DIR / "data" / "cache" / "advisor"

    print(f"\n{'='*60}")
    print(f"[ADVISOR] GENERATING STRATEGIC GUIDANCE")
    print(f"{'='*60}")
    
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    # v12.1 Authority Assertion: Handshake between Reference and Advisor
    from engine.brain import REFERENCE_CACHE_VERSION
    blueprint_ver = blueprint.contract.get("version", "0.0") if blueprint.contract else "0.0"
    if blueprint_ver != REFERENCE_CACHE_VERSION:
        print(f"  âŒ AUTHORITY FAILURE: Blueprint version ({blueprint_ver}) != Required ({REFERENCE_CACHE_VERSION})")
        print(f"  âš ï¸ Skipping strategic guidance. Please re-analyze reference {blueprint.contract.get('source_hash', 'unknown') if blueprint.contract else ''}")
        return None
    
    print(f"  ðŸ¤ Authority Confirmed: v{blueprint_ver} Director-Soul Intelligence active.")
    
    ref_hash = hashlib.md5(
        (blueprint.narrative_message + str(blueprint.segments)).encode()
    ).hexdigest()[:12]
    
    library_hash = hashlib.md5(
        "".join(sorted(c.filename for c in clip_index.clips)).encode()
    ).hexdigest()[:12]
    
    cache_file = cache_dir / f"advisor_{ref_hash}_{library_hash}.json"
    
    if not force_refresh and cache_file.exists():
        try:
            print(f"  ðŸ“¦ Loading cached advisor hints...")
            data = json.loads(cache_file.read_text(encoding='utf-8'))
            
            cache_version = data.get("cache_version", "1.0")
            if cache_version != "4.0":
                print(f"  âš ï¸ Cache version mismatch ({cache_version} vs 4.0), regenerating...")
                cache_file.unlink()
            else:
                hints = AdvisorHints(**data)
                print(f"  âœ… Loaded from cache: {cache_file.name}")
                return hints
        except Exception as e:
            print(f"  âš ï¸ Cache corrupted, regenerating: {e}")
    
    print(f"  ðŸ§  Calling Gemini for strategic guidance...")
    
    blueprint_summary = _format_blueprint_summary(blueprint)
    library_summary = _format_clip_library_summary(clip_index)
    
    prompt = ADVISOR_PROMPT.format(
        blueprint_summary=blueprint_summary,
        clip_library_summary=library_summary,
        scarcity_report=json.dumps(scarcity_report or {}, indent=2)
    )
    
    for attempt in range(GeminiConfig.MAX_RETRIES):
        try:
            model = initialize_gemini()
            
            rate_limiter.wait_if_needed()
            response = model.generate_content([prompt])
            
            if not response.candidates or response.candidates[0].finish_reason != 1:
                reason = "UNKNOWN"
                if response.candidates:
                    from google.generativeai.types import FinishReason
                    reason = FinishReason(response.candidates[0].finish_reason).name
                raise ValueError(f"Gemini blocked the response. Reason: {reason}")
            
            data = _parse_json_response(response.text)
            
            cached_at = datetime.utcnow().isoformat()
            
            # Parse arc stage guidance (intent-driven)
            arc_guidance = {}
            for stage, guidance_data in data.get('arc_stage_guidance', {}).items():
                try:
                    # Handle both old "recommended_clips" and new "exemplar_clips"
                    if 'exemplar_clips' in guidance_data:
                        guidance_data['recommended_clips'] = guidance_data['exemplar_clips']
                    arc_guidance[stage] = ArcStageGuidance(**guidance_data)
                except Exception as e:
                    print(f"  âš ï¸ Failed to parse guidance for {stage}: {e}")
            
            # Parse narrative subject lock (v9.5+)
            from models import NarrativeSubject
            primary_subject = None
            if data.get('primary_narrative_subject'):
                try:
                    primary_subject = NarrativeSubject(data['primary_narrative_subject'])
                except ValueError:
                    pass
            
            allowed_subjects = []
            for s in data.get('allowed_supporting_subjects', []):
                try:
                    allowed_subjects.append(NarrativeSubject(s))
                except ValueError:
                    pass

            hints = AdvisorHints(
                text_overlay_intent=data.get('text_overlay_intent', ''),
                dominant_narrative=data.get('dominant_narrative', ''),
                
                primary_narrative_subject=primary_subject,
                allowed_supporting_subjects=allowed_subjects,
                subject_lock_strength=float(data.get('subject_lock_strength', 1.0)),
                
                arc_stage_guidance=arc_guidance,
                library_alignment=data.get('library_alignment', {}),
                editorial_strategy=data.get('editorial_strategy', ''),
                remake_strategy=data.get('remake_strategy', ''),
                cached_at=cached_at,
                cache_version="4.0"
            )
            
            cache_file.write_text(hints.model_dump_json(indent=2), encoding='utf-8')
            print(f"  âœ… Advisor hints generated and cached")
            print(f"  ðŸ’¡ Text Overlay Intent: {hints.text_overlay_intent}")
            print(f"  ðŸ“– Dominant Narrative: {hints.dominant_narrative}")
            print(f"  ðŸŽ¯ Editorial Strategy: {hints.editorial_strategy}")
            
            return hints
            
        except Exception as e:
            print(f"  âš ï¸ Advisor attempt {attempt + 1} failed: {e}")
            if _handle_rate_limit_error(e, "advisor"):
                continue
            if attempt == GeminiConfig.MAX_RETRIES - 1:
                print(f"  âŒ Advisor failed after all retries")
                print(f"  âš™ï¸ Falling back to base matcher (no advisor influence)")
                return None
            time.sleep(GeminiConfig.RETRY_DELAY)
    
    return None


def compute_advisor_bonus(
    clip: ClipMetadata,
    segment: Segment,
    blueprint: StyleBlueprint,
    advisor_hints: Optional[AdvisorHints]
) -> int:
    """
    Translate Advisor's editorial intent into scoring pressure.
    
    This is NOT rule enforcement - it's priority weighting based on
    whether the clip matches the editorial intent for this arc stage.
    
    Args:
        clip: Candidate clip being scored
        segment: Current segment being filled
        blueprint: Reference analysis with narrative intent
        advisor_hints: Advisor guidance (can be None for graceful degradation)
    
    Returns:
        Bonus score (typically in range -50 to +60)
    """
    if not advisor_hints:
        return 0
    
    bonus = 0
    
    # Get editorial guidance for this arc stage
    guidance = advisor_hints.arc_stage_guidance.get(segment.arc_stage)
    if not guidance:
        return 0
    
    # Check if clip matches PRIMARY EMOTIONAL CARRIER (+60 strong boost)
    primary_match = _matches_intent(clip, guidance.primary_emotional_carrier)
    if primary_match:
        bonus += 60
    
    # Check if clip is SUPPORTING MATERIAL (+15 mild boost)
    supporting_match = _matches_intent(clip, guidance.supporting_material)
    if not primary_match and supporting_match:
        bonus += 15
    
    # Check if clip DILUTES INTENT (-50 penalty, but not forbidden)
    dilutes_match = _matches_intent(clip, guidance.intent_diluting_material)
    if dilutes_match:
        bonus -= 50
    
    # CRITICAL FIX: For Build-up, if primary carrier mentions "people" but clip has no people,
    # treat it as intent-diluting even if it wasn't explicitly listed
    if segment.arc_stage == "Build-up":
        primary_needs_people = "people" in guidance.primary_emotional_carrier.lower() or \
                              "group" in guidance.primary_emotional_carrier.lower() or \
                              "shared" in guidance.primary_emotional_carrier.lower()
        
        clip_has_people = any("People" in subj for subj in clip.primary_subject)
        
        if primary_needs_people and not clip_has_people and not primary_match:
            # This is a scenic clip in a people-driven Build-up segment
            bonus -= 40  # Penalty for missing the primary carrier
    
    # Boost clips that are specifically recommended as exemplars
    if clip.filename in guidance.recommended_clips:
        bonus += 20
    
    # Content alignment bonuses (from blueprint must_have/should_have)
    exact_must, category_must = _match_content_requirements(
        clip, blueprint.must_have_content
    )
    if exact_must:
        bonus += 20
    elif category_must:
        bonus += 10
    
    exact_should, category_should = _match_content_requirements(
        clip, blueprint.should_have_content
    )
    if exact_should:
        bonus += 10
    elif category_should:
        bonus += 5
    
    # Quality bonus
    if clip.clip_quality >= 4:
        bonus += 5
    
    # Stable moments for Intro/Outro
    if segment.arc_stage in ["Intro", "Outro"]:
        if clip.best_moments:
            energy_key = segment.energy.value.capitalize()
            best_moment = clip.best_moments.get(energy_key)
            if best_moment and best_moment.stable_moment:
                bonus += 10
    
    return bonus


def _matches_intent(clip: ClipMetadata, intent_description: str) -> bool:
    """
    Simple semantic matching between clip metadata and intent description.
    
    This is intentionally fuzzy - we're checking if the clip's semantic
    tags align with the Advisor's editorial reasoning.
    """
    if not intent_description:
        return False
    
    intent_lower = intent_description.lower()
    
    # Check if intent requires people
    intent_needs_people = any(keyword in intent_lower for keyword in [
        "people", "group", "shared", "celebrating", "laughing", "human", "friends"
    ])
    
    clip_has_people = any("People" in subj for subj in clip.primary_subject)
    
    # If intent needs people but clip has none, no match
    if intent_needs_people and not clip_has_people:
        return False
    
    # If intent is about scenic/landscapes and clip is scenic, match
    if any(keyword in intent_lower for keyword in ["scenic", "landscape", "atmospheric", "establishing"]):
        if any("Place" in subj for subj in clip.primary_subject):
            return True
    
    # Check primary_subject for specific matches
    for subject in clip.primary_subject:
        if "People" in subject:
            # People-related intent keywords
            if any(keyword in intent_lower for keyword in [
                "people", "group", "shared", "celebrating", "laughing", "human",
                "connection", "interaction", "friends", "social"
            ]):
                return True
        
        if "Celebration" in subject and "celebrat" in intent_lower:
            return True
        
        if "Travel" in subject and any(keyword in intent_lower for keyword in [
            "journey", "transit", "travel", "moving"
        ]):
            return True
        
        if "Leisure" in subject and any(keyword in intent_lower for keyword in [
            "leisure", "casual", "relaxed"
        ]):
            return True
    
    # Check emotional_tone
    for tone in clip.emotional_tone:
        if tone.lower() in intent_lower:
            return True
    
    # Check narrative_utility
    for utility in clip.narrative_utility:
        if utility.lower() in intent_lower:
            return True
    
    return False


def _match_content_requirements(
    clip: ClipMetadata,
    requirements: list[str]
) -> Tuple[bool, bool]:
    """
    Check if clip matches content requirements.
    
    Uses a two-tier matching system:
    - Exact: Full subject name appears in requirement text
    - Category: Subject category (first part before dash) appears in requirement
    
    Args:
        clip: Clip with primary_subject field
        requirements: List of content requirement strings from reference
    
    Returns:
        Tuple of (exact_match, category_match)
    """
    exact_match = False
    category_match = False
    
    clip_categories = {s.split('-')[0].lower() for s in clip.primary_subject}
    
    for req in requirements:
        req_lower = req.lower()
        
        for subject in clip.primary_subject:
            subject_clean = subject.lower().replace('-', ' ')
            if subject_clean in req_lower or any(part in req_lower for part in subject_clean.split()):
                exact_match = True
                break
        
        for cat in clip_categories:
            if cat in req_lower:
                category_match = True
                break
    
    return exact_match, category_match


def _format_blueprint_summary(blueprint: StyleBlueprint) -> str:
    """
    Format blueprint into a concise summary for the Gemini prompt.
    """
    lines = []
    
    lines.append(f"Duration: {blueprint.total_duration:.1f}s")
    lines.append(f"Editing Style: {blueprint.editing_style}")
    lines.append(f"Emotional Intent: {blueprint.emotional_intent}")
    
    if blueprint.text_overlay:
        lines.append(f"Text Overlay: \"{blueprint.text_overlay}\"")
        if blueprint.text_style:
            lines.append(f"Text Style: {blueprint.text_style}")
    
    if blueprint.color_grading:
        lines.append(f"Color Grading: {blueprint.color_grading}")
    if blueprint.visual_effects:
        lines.append(f"Visual Effects: {', '.join(blueprint.visual_effects)}")
    if blueprint.aspect_ratio:
        lines.append(f"Aspect Ratio: {blueprint.aspect_ratio}")

    lines.append(f"\nNarrative Message: {blueprint.narrative_message}")
    lines.append(f"Intent Clarity: {blueprint.intent_clarity}")
    
    if blueprint.must_have_content:
        lines.append(f"\nMust-Have Content:")
        for item in blueprint.must_have_content:
            lines.append(f"  - {item}")
    
    if blueprint.should_have_content:
        lines.append(f"\nShould-Have Content:")
        for item in blueprint.should_have_content:
            lines.append(f"  - {item}")
    
    if blueprint.avoid_content:
        lines.append(f"\nAvoid Content:")
        for item in blueprint.avoid_content:
            lines.append(f"  - {item}")
    
    lines.append(f"\nPacing Feel: {blueprint.pacing_feel}")
    lines.append(f"Visual Balance: {blueprint.visual_balance}")
    lines.append(f"Arc Description: {blueprint.arc_description}")
    
    arc_stages = {}
    for seg in blueprint.segments:
        stage = seg.arc_stage
        if stage not in arc_stages:
            arc_stages[stage] = []
        arc_stages[stage].append(seg)
    
    lines.append(f"\nArc Stage Breakdown:")
    for stage, segments in arc_stages.items():
        energy_counts = {}
        functions = set()
        for seg in segments:
            energy_counts[seg.energy.value] = energy_counts.get(seg.energy.value, 0) + 1
            if seg.shot_function:
                functions.add(seg.shot_function)
        
        energy_str = ", ".join(f"{count}x {energy}" for energy, count in energy_counts.items())
        func_str = f" [Functions: {', '.join(functions)}]" if functions else ""
        lines.append(f"  {stage}: {len(segments)} segments ({energy_str}){func_str}")
    
    return "\n".join(lines)


def _format_clip_library_summary(clip_index: ClipIndex) -> str:
    """
    Format clip library into a concise summary for the Gemini prompt.
    """
    lines = []
    lines.append(f"Total Clips: {len(clip_index.clips)}\n")
    
    for clip in clip_index.clips:
        clip_info = [
            f"Filename: {clip.filename}",
            f"Duration: {clip.duration:.1f}s",
            f"Energy: {clip.energy.value} (intensity: {clip.intensity})",
            f"Motion: {clip.motion.value}",
            f"Primary Subject: {', '.join(clip.primary_subject)}",
            f"Narrative Utility: {', '.join(clip.narrative_utility)}",
            f"Emotional Tone: {', '.join(clip.emotional_tone)}",
            f"Quality: {clip.clip_quality}/5",
            f"Best For: {', '.join(clip.best_for)}",
        ]
        
        if clip.avoid_for:
            clip_info.append(f"Avoid For: {', '.join(clip.avoid_for)}")
        
        if clip.content_description:
            clip_info.append(f"Content: {clip.content_description}")
        
        lines.append("  " + " | ".join(clip_info))
    
    return "\n".join(lines)
